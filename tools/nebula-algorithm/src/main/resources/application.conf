{
  # Spark relation config
  spark: {
    app: {
        name: LPA
    }
  }

  data: {
    # optional of nebula,csv,json,parquet
    source: csv
    sink: csv
    hasWeight: false
  }

  # Nebula Graph relation config
  nebula: {
    # algo's data source from Nebula
    read: {
        metaAddress: "192.168.2.16:45500"
        space: nb
        partitionNumber: 100
        labels: ["serve"]
        weightCols: ["start_year"]
    }

    # algo result sink into Nebula
    write:{
        graphAddress: "192.168.2.16:3699"
        user:root
        pswd:nebula
        space:nb
        tag:pagerank
        propCol:pr
        colType:double
    }

  }

  local: {
    # algo's data source from Nebula
    read:{
        filePath: "hdfs://192.168.2.16:9000/data/edge/edge.csv"
        srcId:"col1"
        dstId:"col2"
        #weight: "col3"
        header: true
        delimiter:","
    }

    # algo result sink into local file
    write:{
        resultPath:/tmp/lpa
    }
  }


  algorithm: {
    # the algorithm that you are going to executeï¼Œpick one from [pagerank, louvain, connectedcomponent, labelpropagation, shortestpaths, degreestatic, kcore]
    executeAlgo: labelpropagation

    # pagerank parameter
    pagerank: {
        maxIter: 20
        resetProb: 0.15  # default 0.15
    }

    # louvain parameter
    louvain: {
        maxIter: 20
        internalIter: 10
        tol: 0.5
   }

   # connected component parameter  TODO not implemented yet.
    connectedcomponent: {
        maxIter: 20
   }

   # LabelPropagation
    labelpropagation: {
        maxIter: 20
   }

   # ShortestPaths
    shortestpaths: {
        # several vertices to compute the shortest path to all vertices.
        landmarks: "1"
   }


    # vertex degree static
    degreestatic: {}

   # kcore
   kcore:{
        maxIter:10
        degree:1
   }
 }
}
